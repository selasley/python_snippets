{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few short snippets used in Voyager data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def read_rate_file(ftpath: Path, rename: bool = True, uncertainties: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a gzipped rates file from ftecs and create a DataFrame with a DatetimeIndex\n",
    "    from the start time in columns 0-4.  Clean up the ftecs column names if rename\n",
    "    is True and include the U uncertainties columns if uncertainties is True.\n",
    "\n",
    "    :param ftpath: Path to the ftecs rates file\n",
    "    :param rename: Do not include the S0n sector in the colum names if True\n",
    "    :param uncertainties: Include the U columns if True\n",
    "    :return: DataFrame ceated from the rates data with a DatetimeIndex\n",
    "    \"\"\"\n",
    "    if not ftpath.exists():\n",
    "        print(f'{ftpath} not found')\n",
    "        return pd.DataFrame()\n",
    "    df = pd.read_csv(\n",
    "        ftpath,\n",
    "        compression='gzip',\n",
    "        index_col=[0, 1, 2, 3, 4],\n",
    "        na_values=-1,\n",
    "    )\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df.index = pd.to_datetime(\n",
    "        ['{} {} {} {} {}'.format(*tup) for tup in df.index.to_numpy()],\n",
    "        format='%Y %j %H %M %S.%f',\n",
    "    )\n",
    "    df. insert(5, 'End_date', pd.to_datetime(\n",
    "        ['{} {} {} {} {}'.format(*tup) for tup in df.iloc[:, :5].to_numpy()],\n",
    "        format='%Y.0 %j.0 %H.0 %M.0 %S.%f',\n",
    "    ))\n",
    "    ratename = df.iloc[0, [7]].index[0]\n",
    "    ftrate = ratename[: ratename.find('RS0')]\n",
    "    if rename:\n",
    "        df.columns = df.columns.str.replace(f'{ftrate}R', ftrate[-2:])\n",
    "    if not uncertainties:\n",
    "        df = df[[col for col in df.columns if not col[-1] == 'U']]\n",
    "    return df.loc[:, 'End_date' : df.columns[-3]]\n",
    "\n",
    "####\n",
    "ftfile = Path('data/V11999001B68.CSV.GZ')\n",
    "ratesdf = read_rate_file(ftfile)\n",
    "ratesdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S0n in the rate column names is the motor step.  This routine \"pivots\" the DataFrame to put the rate data and motor step into columns.  Useful for combining rate data from multiple Brr files into a format that's easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def step_to_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a DataFrame containing a Step column containing the motor step and\n",
    "    a column containing the rate data.  There is probably a better way to do this\n",
    "    :param df: DataFrame containing rates data starting in column 2 labeled\n",
    "               RateS0n where n is the motor step\n",
    "    :return: DataFrame with Rate and motor step in columns 2 and 3\n",
    "    \"\"\"\n",
    "    rate = df.columns[3]\n",
    "    rate = rate[: rate.find('S0')]\n",
    "    step_df = (\n",
    "        df.iloc[:, :2]\n",
    "          .join(df.iloc[:, 2:]\n",
    "                  .stack()\n",
    "                  .reset_index(level=1)\n",
    "                )\n",
    "          .rename(columns={'level_1': 'Step', 0: rate})\n",
    "    )\n",
    "    step_df['dd'] = step_df['dd'].fillna(-1)\n",
    "    step_df['Step'] = step_df['Step'].str[-1].astype(int)\n",
    "    return step_df\n",
    "\n",
    "\n",
    "####\n",
    "# read singles rates files, convert to Rate & Step format and concat to make\n",
    "# a single DataFrame with step and rates data\n",
    "(pd.concat(\n",
    "     [\n",
    "         step_to_column(read_rate_file(Path(f'data/V11999001B{rr}.CSV.GZ')))\n",
    "         for rr in range(68, 76)\n",
    "     ],\n",
    " )\n",
    "   .rename_axis('SCET')\n",
    "   .sort_values(by=['SCET', 'dd', 'Step'])\n",
    "   .head(13)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Voyager pipeline updates text files containing flux data and plots of the data.  These snippets read the data from the flux file and plots it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def readdb(dbfile: Path):\n",
    "    with open(dbfile, 'r') as dbfile:\n",
    "        # read 7 header lines and keep the 8th line containing column names\n",
    "        for _ in range(8):\n",
    "            line = dbfile.readline()\n",
    "        colnames = line[1:].split()\n",
    "        usecols = ['s/c', 'Start_Year', 'Start_Day', 'End_Year', 'End_Day',\n",
    "                   'Std._Year', 'Z', 'E/n', 'Emin', 'Emax', '(delta)E/2',\n",
    "                   'Flux', 'sigma']\n",
    "        df = (pd.read_csv(dbfile,\n",
    "                          skiprows=1,\n",
    "                          delim_whitespace=True,\n",
    "                          usecols=usecols,\n",
    "                          names=colnames,\n",
    "                          index_col=['s/c', 'Start_Year', 'Start_Day', 'Z'],\n",
    "                          )\n",
    "                .rename(columns={'(delta)E/2': '∆E/2'})\n",
    "                .sort_index()\n",
    "              )\n",
    "    return df\n",
    "\n",
    "####\n",
    "readdb(dbfile=Path('data/vmaster_year.txt')).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "traces = {1: ('H', 'o', 7, 'r'),\n",
    "          2: ('He', 's', 7, 'darkviolet'),\n",
    "          6: ('C', 'd', 7, 'k'),\n",
    "          7: ('N', 'D', 6, 'b'),\n",
    "          8: ('O', '^', 7, 'lime'),\n",
    "          10: ('Ne', '<', 7, 'peru'),\n",
    "          12: ('Mg', 'H', 7, 'fuchsia'),\n",
    "          14: ('Si', '>', 7, 'seagreen'),\n",
    "          16: ('S', 'p', 8, 'darkorange'),\n",
    "          18: ('Ar', '*', 11, 'aqua'),\n",
    "          26: ('Fe', 'v', 7, 'crimson'),\n",
    "          }\n",
    "\n",
    "def restore_minor_ticks_log_plot(\n",
    "        ax=None, n_subticks=9\n",
    "    ) -> None:\n",
    "        \"\"\"For axes with a logrithmic scale where the span (max-min) exceeds\n",
    "        10 orders of magnitude, matplotlib will not set logarithmic minor ticks.\n",
    "        If you don't like this, call this function to restore minor ticks.\n",
    "\n",
    "        Args:\n",
    "            ax:\n",
    "            n_subticks: Number of Should be either 4 or 9.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        https://stackoverflow.com/questions/44078409/matplotlib-semi-log-plot-minor-tick-marks-are-gone-when-range-is-large\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            print('you must pass an ax to restore_minor_ticks_log_plot')\n",
    "            return\n",
    "        # Method from SO user importanceofbeingernest at\n",
    "        # https://stackoverflow.com/a/44079725/5972175\n",
    "        locmaj = mpl.ticker.LogLocator(base=10, numticks=1000)\n",
    "        ax.xaxis.set_major_locator(locmaj)\n",
    "        locmin = mpl.ticker.LogLocator(\n",
    "            base=10.0, subs=np.linspace(0, 1.0, n_subticks + 2)[1:-1], numticks=1000\n",
    "        )\n",
    "        ax.yaxis.set_minor_locator(locmin)\n",
    "        ax.yaxis.set_minor_formatter(mpl.ticker.NullFormatter())\n",
    "\n",
    "def plot_a_spectra(df: pd.DataFrame, sc: int, year: int, start_day: int):\n",
    "    end_day = df.loc[(start_day,), 'End_Day'].unique()[0]\n",
    "    fig = mpl.figure.Figure(figsize=(7.5, 5.5), )\n",
    "    ax = fig.add_subplot(1, 1, 1, xscale='log', yscale='log',)\n",
    "    ax.set_position([0.135, 0.145, 0.68, 0.725])\n",
    "    for z in df.index.get_level_values('Z').unique():\n",
    "        (elem, mrkr, siz, colr) = traces.get(z)\n",
    "        zdf = df.loc[(start_day, z), :]\n",
    "        ax.errorbar(zdf['E/n'], zdf['Flux'],\n",
    "                    yerr=zdf['sigma'], xerr=zdf['∆E/2'],\n",
    "                    label=elem, marker=mrkr, ms=siz, lw=0,\n",
    "                    mfc='none', mec=colr, mew=0.6,\n",
    "                    elinewidth=0.75, ecolor=colr,\n",
    "                    )\n",
    "    if sc == 1:\n",
    "        bboxx = 1.003\n",
    "    else:\n",
    "        bboxx = 0.92\n",
    "    # https://stackoverflow.com/questions/14297714/matplotlib-dont-show-errorbars-in-legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles = [h[0] if isinstance(h, mpl.container.ErrorbarContainer) else h for h in handles]\n",
    "    ax.legend(handles, labels, fontsize=12, ncol=3 - sc, frameon=False,\n",
    "              loc='center right',\n",
    "              bbox_to_anchor=(bboxx, 0.51), bbox_transform=fig.transFigure,\n",
    "              labelcolor=[val[-1] for val in traces.values()],\n",
    "              handletextpad=0.01, columnspacing=0.25, labelspacing=.25)\n",
    "    ax.text(.20, 25, f'Voyager {sc}\\nLECP', ha='center',\n",
    "            fontsize=18, fontweight='medium')\n",
    "    ax.set_title(f'{year}: {start_day} – {end_day}', y=1.02,\n",
    "                 fontsize=26, fontweight='medium')\n",
    "    ax.text(24, 24, 'Exclude Sectors 4,8,U', fontsize=8, c='r')\n",
    "    ax.set_ylabel('Flux ( 1 / $\\\\mathdefault{cm^{2}}$–sr–s–MeV / nuc )', fontsize=14)\n",
    "    ax.set_xlabel('Energy / nucleon (MeV / nuc)', fontsize=14)\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    ax.tick_params(axis='both', which='major', right=True, top=True, length=7.5)\n",
    "    ax.tick_params(axis='both', which='minor', top=True, left=True, right=True, length=4)\n",
    "\n",
    "    ax.set_xlim([0.1, 100])\n",
    "    ax.set_ylim([1e-8, 10])\n",
    "    ax.set_yticks(np.logspace(-8, 1, 10))\n",
    "    restore_minor_ticks_log_plot(ax=ax)\n",
    "    tick_labels = [f'$\\mathdefault{{10^{{{decade}}}}}$' for decade in range(-8, 2)]\n",
    "    ax.yaxis.set_ticklabels(tick_labels, ha='left')\n",
    "    ax.yaxis.set_tick_params(pad=27)\n",
    "    scalar_fmtr = mpl.ticker.ScalarFormatter()\n",
    "    ax.xaxis.set_major_formatter(scalar_fmtr)\n",
    "\n",
    "    ax.text(0.036, 1.3e-9, f'{dt.datetime.today():%b %d, %Y}', fontsize=7)\n",
    "    return fig\n",
    "\n",
    "####\n",
    "sc = 1\n",
    "year = 1999\n",
    "specdf = readdb(dbfile=Path('data/vmaster_year.txt')).loc[sc, year]\n",
    "plot_a_spectra(df=specdf, sc=sc, year=year, start_day=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
